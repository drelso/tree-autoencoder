nohup: ignoring input

=================== MODEL PARAMETERS: =================== 

general_data_dir:                /home/diegor/data/
use_data_subset:                 True
data_subset_size:                0.5
bnc_data_dir:                    /home/diegor/data/British_National_Corpus/bnc_full_processed_data/
bnc_data:                        /home/diegor/data/British_National_Corpus/bnc_full_processed_data/bnc_full_proc_data.txt
bnc_tags:                        /home/diegor/data/British_National_Corpus/bnc_full_processed_data/bnc_full_proc_data_tags.txt
bnc_subset_data:                 /home/diegor/data/British_National_Corpus/bnc_full_processed_data/bnc_full_proc_data_shffl_sub-5.txt
bnc_subset_tags:                 /home/diegor/data/British_National_Corpus/bnc_full_processed_data/bnc_full_proc_data_shffl_sub-5_tags.txt
dataset_path:                    data/bnc_full_proc_data_shffl_sub-5_seqlist_deptree.json
counts_file:                     /home/diegor/data/British_National_Corpus/bnc_full_processed_data/counts_bnc_full_proc_data_shffl_sub-5.csv
vocab_cutoff:                    5
num_dataset:                     data/num_voc-5_bnc_full_proc_data_shffl_sub-5_seqlist_deptree.json
embedding_dim:                   768
word_emb_dim:                    300
num_layers:                      1
dec_dropout:                     0
num_epochs:                      3
split_ratios:                    [0.8, 0.1, 0.1]
batch_size:                      5
sort_train_val_data:             True
shuffle_train_val_data:          True
repeat_train_val_iter:           False
all_models_dir:                  model/
model_name:                      bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3
model_dir:                       model/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3/
model_path:                      model/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3.pth
checkpoints_dir:                 model/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3/checkpoints/
checkpoints_path:                model/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3/checkpoints/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3
word_embs_path:                  model/bnc_full_proc_data_shffl_sub-5_seqlist_deptree_voc-5_w-emb-300_btch-5_epch-3/tree_input_word_embs.npy

=================== / MODEL PARAMETERS: =================== 

Using data subset: 50.0% of full dataset
Found existing dataset subset at /home/diegor/data/British_National_Corpus/bnc_full_processed_data/bnc_full_proc_data_shffl_sub-5.txt and subset tags at /home/diegor/data/British_National_Corpus/bnc_full_processed_data/bnc_full_proc_data_shffl_sub-5_tags.txt 

Found existing dependency trees and sequence lists dataset file at data/bnc_full_proc_data_shffl_sub-5_seqlist_deptree.json

Found existing word counts file at /home/diegor/data/British_National_Corpus/bnc_full_processed_data/counts_bnc_full_proc_data_shffl_sub-5.csv

Constructing vocabulary from counts file in /home/diegor/data/British_National_Corpus/bnc_full_processed_data/counts_bnc_full_proc_data_shffl_sub-5.csv
98253 unique tokens in vocabulary with (with minimum frequency 5)
No numericalised file found at data/num_voc-5_bnc_full_proc_data_shffl_sub-5_seqlist_deptree.json, creating numericalised file from dataset at data/bnc_full_proc_data_shffl_sub-5_seqlist_deptree.json
Writing numericalised dataset to data/num_voc-5_bnc_full_proc_data_shffl_sub-5_seqlist_deptree.json
100000 lines written
200000 lines written
300000 lines written
400000 lines written
500000 lines written
600000 lines written
700000 lines written
800000 lines written
900000 lines written
1000000 lines written
1100000 lines written
1200000 lines written
1300000 lines written
1400000 lines written
1500000 lines written
1600000 lines written
1700000 lines written
1800000 lines written
1900000 lines written
2000000 lines written
2100000 lines written
Finished writing file: 2192152 lines
